<!DOCTYPE html>
<html lang="en">
	<head>
		<!-- Google tag (gtag.js) -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-RENR9BKCTC"></script>
		<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'G-RENR9BKCTC');
		</script>

		<title>2nd Workshop on Urban Scene Modeling: Where Vision Meets Photogrammetry and Graphics</title>
		<link rel="icon" type="image/x-icon" href="images/logos/favicon.ico">

		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>  
		<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
        <meta name="description" content="CVPR 2025 Workshop on Urban Scene Modeling: Where Vision Meets Photogrammetry and Graphics.">
        <meta name="keywords" content="CVPR, Structured Reconstruction, 3D Reconstruction, CVPR Workshop, Urban Scene Modeling, Photogrammetry, Graphics, NeRF, SfM, SLAM, Gaussian Splatting, Radiance Fields">
        <meta name="author" content="Jack Langerman et al.">
        <meta name="viewport" content="width=device-width, initial-scale=0.75">
        <meta http-equiv="Cache-control" content="public" max-age="86400">

		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <link rel="stylesheet" href="css/main.css">
	</head>
	<body>
    <div class="container">

        <header class="row text-center header info">
            <img src="images/background.jpg" alt="Urban Scene Modeling Workshop" class="text-center banner">
            <h1>2nd Workshop on Urban Scene Modeling</h1>
            <h3>Where Vision Meets Photogrammetry and Graphics - CVPR 2025</h3>
        </header>
    
        <section id="about">
			<div class="row">
				<div class="col-sm-12 col-md-3">
					<div class="section-header text-left">
						<img src="images/logos/logo-temp.webp" alt="CVPR Workshop Urban Scene Modeling 2025"
							 class="img-responsive" >
					</div>
				</div>
				<div class="col-sm-12 col-md-9">
					<p style="text-align: justify;">
						3D reconstruction and modeling are central to modern computer vision, with rapid 
						urbanization creating urgent social and environmental challenges that demand 
						innovative solutions. While substantial progress has been made in reconstructing 
						basic 3D structures from images and point clouds, the next frontier lies in advancing 
						structured and semantic reconstructionâ€”moving beyond low-level 3D information to 
						produce high-level, parametric models that capture both the structure and semantics 
						of human environments.
					</p>
					<p style="text-align: justify;">
						This workshop aims to bridge the gap between state-of-the-art 3D scene modeling and 
						structured, semantic 3D reconstruction by bringing together researchers from 
						photogrammetry, computer vision, generative models, learned representations, and 
						computer graphics. Through invited talks, spotlight presentations, workshop challenges, 
						and a poster session, we will foster interdisciplinary interaction and empower the next 
						generation of 3D reconstruction technologies by integrating techniques from multi-view 
						learning, geometric modeling, and machine perception. We welcome original contributions 
						in structured reconstruction, learning-based approaches, and all areas related to urban 
						scene modeling.
					</p>
				</div>
			</div>
		</section>

        <section id="news">
			<div class="row">
				<h2>News</h2>
				<ul>
					<li>Jan 2, 2025: Exciting news coming soon! ðŸŽ‰</li>
					<li>Dec 20, 2024: Workshop is accepted for CVPR 2025 ðŸŽ‰</li>
				</ul>
			</div>
        </section>

        <section id="callforpapers">
			<div class="row">
				<h2>Call for Papers</h2>
                <div class="col-sm-12 col-md-12" >
                    <p>We invite submissions of original research related to urban scene modeling. Topics of interest include, but are not limited to:</p>
                    <ul>
                        <li>Structured 3D Reconstruction/Modeling of human environments, including indoor and outdoor spaces, from sparse, noisy, or partial point clouds and images</li>
                        <li>Semantic, Instance, and Panoptic Segmentation and Parsing of 3D point clouds and images in complex human-centered environments</li>
                        <li>Fusion of Images and Point Clouds to improve the accuracy, detail, and structure of human-centric 3D scene modeling</li>
                        <li>Structured Representation of 3D Scenes, including parametric (e.g., CAD, B-Rep, Wireframe, etc.) models for buildings, interiors, and other human-made structures</li>
                        <li>Neural Implicit Representations for efficient and scalable modeling of large human environments</li>
                        <li>Learning Priors for Structured 3D Modeling, focusing on generating plausible, real-world human environments with structural consistency</li>
                        <li>Generative Models for Occlusion-Free Image Generation, enabling realistic texture mapping and enhanced 3D model quality</li>
                        <li>Multiview 3D Matching and Registration techniques for capturing and integrating scans of complex human spaces</li>
                        <li>Pose Estimation and Structured 3D Recovery from sparse image sets, with applications in architecture, robotics, and other domains</li>
                        <li>Differentiable Rendering and Occlusion Reasoning in human environments, such as indoor spaces, cityscapes, and public infrastructure</li>
                        <li>Applications of Structured and Semantic 3D Reconstruction in smart cities, construction, autonomous navigation, and digital twins</li>
                        <li>Benchmarks and Datasets for large-scale 3D modeling of human environments, driving new challenges and setting the standard for the field</li>
                    </ul>
                    <p>
                    We will accept submissions on two tracks: extended abstract submissions (up to 4 pages) and full papers (up to 8 pages) in the standard CVPR format. Accepted submissions will be presented as posters, and some will be selected for spotlight talks.
                    </p>
                    <p>
                    Paper submission deadline: March 24, 2025. via CMT
                    </p>
                    <p>
                    More details about the submission process will be announced soon.
                    </p>
                </div>
            </div>


			<div class="row">
				<div class="col-sm-12 col-md-12">
					<h3 id="wheretosubmit">Where to Submit</h3>
					<p>All submissions will be handled through the CMT platform and submitted via <a target="_blank" href="http://cmt3.research.microsoft.com/USM3D2025/">this link</a></p>
					
					<a target="_blank" href="http://cmt3.research.microsoft.com/USM3D2025/"><h2>Submit Here</h2></a>

					<h3>How to Submit</h3>
					<p>Authors should submit their papers through CMT. Each submission must include:</p>
					<ul>
						<li>The paper in PDF format following the CVPR format</li>
						<li>Supplementary materials (optional)</li>
						<li>Authors' information including names, affiliations, and contact details</li>
					</ul>
		
					<h3>Submission Guidelines</h3>
					<ul>
						<li>Papers must be submitted in PDF format</li>
						<li>Papers must follow the CVPR format</li>
						<li>Extended abstracts should be up to 4 pages (excluding references)</li>
						<li>Full papers should be up to 8 pages (excluding references)</li>
						<li>Supplementary material is allowed but should be limited to 100MB</li>
						<li>All submissions must be in English</li>
					</ul>
		
					<h3>Author Guidelines</h3>
					<ul>
						<li>At least one author of each accepted paper must register for the workshop and present the paper</li>
						<li>Authors are responsible for ensuring that their submissions do not violate any publication agreements or copyrights</li>
						<li>Double submissions are not allowed</li>
						<li>Papers will be reviewed by at least two expert reviewers</li>
					</ul>
		
					<h3>Important Dates</h3>
					<ul>
						<li>Paper submission deadline: March 24, 2025</li>
						<li>Notification to authors: April 15, 2025</li>
						<li>Camera-ready deadline: April 30, 2025</li>
					</ul>

					<div>
						<p><strong>Acknowledgment:</strong> The Microsoft CMT service was used for managing the peer-reviewing process for this conference. This service was provided for free by Microsoft and they bore all expenses, including costs for Azure cloud services as well as for software development and support.</p>
					</div>
				</div>
			</div>
		</section>


        <section id="challenge">
			<div class="row">
				<h2>Challenges</h2>
				<!-- <div class="col-sm-12 col-md-3" style="padding: 0;"> -->
				<div>
				<h3 style="margin-top: 0;">2nd Building3D Challenge</h3>
				<div>
					<div class="section-header text-left">
						<img src="images/logos/hf.png" alt="Building3D Challenge" style="margin-top: 2em;" >
					</div>
				<!-- </div> -->
				<!-- <div class="col-sm-12 col-md-9"> -->
                    <!-- <h3 style="margin-top: 0;">2nd Building3D Challenge</h3> -->
					<!-- <p style="text-align: justify;">As part of this workshop, we are hosting the -->
					<p>As part of this workshop, we are hosting the
                        <b><a target="_blank" href="https://huggingface.co/spaces/Building3D/2ndBuilding3DChallengeCVPR2025USM3DWorkshop">Building3D challenge</a></b>.
                        Building3D is an urban-scale publicly available dataset consisting of more than 160 thousand buildings
                        with corresponding point clouds, meshes, and wireframe models covering 16 cities in Estonia. For this challenge,
                        approximately 36, 000 buildings from the city of Tallinn are used as the training and testing dataset. Among them
                        , we selected 6000 relatively dense and structurally simple buildings as the Entry-level dataset. The wireframe
                        model is composed of points and edges representing shape and outline of the object. We require algorithms to take
                        the original point cloud as input and regress the wireframe model. For the evaluation, the metrics of mean
                        precision and recall are employed to evaluate accuracy of both points and edges, and overall offset of the
                        model is calculated. Additionally, the wireframe edit distance (WED) is used as an additional metric to
                        evaluate the accuracy of generated wireframe models. <b>In contrast to the first Building3D Challenge,
                            a new test dataset with entirely different building styles from the Building3D dataset will be used to evaluate the submissions. Enjoy &#128512;.</b>
                    </p>
					<h3>Awards & Submissions</h3>
						<p style="text-align: justify;">
							The winning submission will receive a cash prize provided by the workshop sponsor and the chosen
							finalists will be invited to present their research in the workshop. The prerequisite to receive
							a money prize is to provide a write-up detailing their solution by a submission to the workshop,
							in the form of <b>an extended abstract (4 pages) or a full paper (8 pages)</b>, as well as <b>the code
							required to generate a winning submission under CC BY4.0 license</b>.
						</p>
						<p style="text-align: justify;">There is a <b>$ 10,000</b> prize pool for this challenge.</p>
						<ul>
							<li>1st Place: <b>$5,000</b></li>
							<li>2nd Place: <b>$3,000</b></li>
							<li>3rd Place: <b>$1,000</b></li>
							<li>Additional Prizes: <b>$500</b></li>
						</ul>
						<p style="text-align: justify;">Please see the <a href="https://huggingface.co/spaces/Building3D/2ndBuilding3DChallengeCVPR2025USM3DWorkshop">Competition Rules</a> for additional information.</p>
						<p>We thank <span style="color: gold;  font-weight: bold;">gold sponsor </span><a href="http://www.iskyfly.com/">Intelligence.Ally Technology</a> and
                            <span style="color: silver;  font-weight: bold;">silver sponsor </span><a href="http://www.wucesi.com/">Shenzhen Wuce Space Information Co., Ltd</a> for their generous sponsorship of this competition.</p>
					<h3>Important Dates</h3>
						<p style="text-align: justify;">
							March 1 2025, Sat.: &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;Competition starts<br>
							May 25 2025, Sun.: &nbsp;&nbsp;&nbsp;&nbsp; Competition ends<br>
							May 29 2025,  Thu.: &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; Notification to Participants<br>
							June 1 2025,  Sun.: &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; Writeup Deadline<br>
						</p>
				</div>
			</div>
        </section>

        <section id="organizers">
            <h2>Organizers</h2>
            <div class="row text-center">
                <div class="col-xs-6 col-sm-3">
                    <a target="_blank" href="https://profiles.ucalgary.ca/ruisheng-wang">
                        <img src="images/organizers/ruisheng-wang.jpg" alt="Ruisheng Wang" class="img-circle headshot">
                        <span class="name">Ruisheng <br> Wang</span>
                        <span class="affiliation">Professor <br> Shenzhen University</span>
                    </a>
                </div>
                <div class="col-xs-6 col-sm-3">
                    <a target="_blank" href="https://jackml.com">
                        <img src="images/organizers/jack-langerman.png" alt="Jack Langerman" class="img-circle headshot">
                        <span class="name">Jack <br> Langerman</span>
                        <span class="affiliation">Applied Researcher <br> Apple</span>
                    </a>
                </div>
                <div class="col-xs-6 col-sm-3">
                    <a target="_blank" href="https://ilkedemir.weebly.com">
                        <img src="images/organizers/ilke-demir.png" alt="Ilke Demir" class="img-circle headshot">
                        <span class="name">Ilke <br> Demir</span>
                        <span class="affiliation">Senior Research Scientist <br> Intel Corporation</span>
                    </a>
                </div>
                <div class="col-xs-6 col-sm-3">
                    <a target="_blank" href="https://dmytro.ai">
                        <img src="https://dmytro.ai/photo.jpg" alt="Dmytro Mishkin" class="img-circle headshot">
                        <span class="name">Dmytro <br> Mishkin</span>
                        <span class="affiliation">Researcher <br> Czech Technical University in Prague</span>
                    </a>
                </div>
            </div>
            <div class="row text-center">
                <div class="col-xs-6 col-sm-3">
                    <a target="_blank" href="https://www.imperial.ac.uk/people/t.birdal">
                        <img src="images/organizers/tolga-birdal.jpg" alt="Tolga Birdal" class="img-circle headshot">
                        <span class="name">Tolga <br> Birdal</span>
                        <span class="affiliation">Assistant Professor <br> Imperial College London</span>
                    </a>
                </div>
                <div class="col-xs-6 col-sm-3">
                    <a target="_blank" href="https://saup.szu.edu.cn/info/1091/1415.htm">
                        <img src="images/organizers/renzhong-guo.jpg" alt="Renzhong Guo" class="img-circle headshot">
                        <span class="name">Renzhong <br> Guo</span>
                        <span class="affiliation">Professor <br> Shenzhen University</span>
                    </a>
                </div>
                <div class="col-xs-6 col-sm-3">
                    <a target="_blank" href="https://shangfenghuang.github.io">
                        <img src="images/organizers/shangfeng-huang.png" alt="Shangfeng Huang" class="img-circle headshot">
                        <span class="name">Shangfeng <br> Huang</span>
                        <span class="affiliation">Researcher <br> University of Calgary</span>
                    </a>
                </div>
                <div class="col-xs-6 col-sm-3">
                    <a target="_blank" href="https://www.linkedin.com/in/seanxiangma/">
                        <img src="images/organizers/xiang-ma.png" alt="Xiang Ma" class="img-circle headshot">
                        <span class="name">Xiang <br> Ma</span>
                        <span class="affiliation">Head of Research <br> Amazon Web Services</span>
                    </a>
                </div>
            </div>
            <div class="row text-center">
                <div class="col-xs-6 col-sm-3">
                    <a target="_blank" href="https://www.umr-lastig.fr/clement-mallet/">
                        <img src="images/organizers/clement-mallet.jpeg" alt="Clement Mallet" class="img-circle headshot">
                        <span class="name">Clement <br> Mallet</span>
                        <span class="affiliation">Research Scientist <br> LASTIG</span>
                    </a>
                </div>
                <div class="col-xs-6 col-sm-3">
                    <a target="_blank" href="https://users.encs.concordia.ca/~wayang/">
                        <img src="images/organizers/yang-wang.jpeg" alt="Yang Wang" class="img-circle headshot">
                        <span class="name">Yang <br> Wang</span>
                        <span class="affiliation">Associate Professor <br> Concordia University</span>
                    </a>
                </div>
                <div class="col-xs-6 col-sm-3">
                    <a target="_blank" href="https://www.yuzhonghuang.org/">
                        <img src="images/organizers/yuzhong-huang.jpeg" alt="Yuzhong Huang" class="img-circle headshot">
                        <span class="name">Yuzhong <br> Huang</span>
                        <span class="affiliation">Researcher <br>University of Southern California</span>
                    </a>
                </div>
            </div>
    </div>
    </section>

    <section id="links" class="container">
        <h2>Links</h2>
        <ul>
            <li><p>Previous websites: <a href="./2024/index.html">2024</a></p></li>
            <li><p>This is a <a href="http://cvpr2025.thecvf.com/">CVPR 2025</a> workshop</p></li>
        </ul>
    </section>

    <footer class="text-center footer">
        <p>All Rights Reserved. &copy; 2025</p>
    </footer>

    </div>

</body>
</html>
